# Heartbeat Monitor: Agente de Monitorizaci√≥n de Alto Rendimiento

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.14-blue.svg" alt="Python 3.14">
  <img src="https://img.shields.io/badge/Docker-passing-brightgreen.svg" alt="Docker Build Status">
</p>

Un agente de monitorizaci√≥n ligero, modular y concurrente dise√±ado espec√≠ficamente para entornos Dockerizados. Este sistema no solo verifica la disponibilidad, sino que optimiza la latencia de red y gestiona el estado de los servicios con una arquitectura resiliente.

Desarrollado en **Python 3.14 (Alpine)**, enfocado en la eficiencia de recursos y la precisi√≥n de m√©tricas.

## üöÄ Caracter√≠sticas T√©cnicas Destacadas

M√°s que un simple script de "ping", este proyecto implementa patrones de ingenier√≠a para resolver problemas comunes en monitorizaci√≥n distribuida:

* **‚ö° Arquitectura Concurrente:** Implementaci√≥n de `ThreadPoolExecutor` para paralelizar operaciones de I/O (solicitudes HTTP, consultas a sockets Docker), desacoplando la recolecci√≥n de m√©tricas del bloqueo de red y garantizando ciclos de ejecuci√≥n precisos.
* **üß† Red Inteligente (Smart Networking):**
  * **DNS Override & Host Injection:** Mecanismo capaz de interceptar tr√°fico hacia servicios internos, resolviendo directamente a IPs locales e inyectando cabeceras `Host`. Esto elimina la latencia de resoluci√≥n DNS externa y el overhead de SSL en redes internas (reducci√≥n de ~50ms a ~2ms).
  * **IPv4 Enforcement:** Adaptadores HTTP personalizados a nivel de transporte para mitigar los retrasos de resoluci√≥n IPv6 comunes en contenedores Alpine Linux.
* **üê≥ Protocolo Docker Nativo:** Soporte para el esquema `docker:<container_name>`, permitiendo verificaciones de salud directas contra el socket Unix de Docker (`/var/run/docker.sock`) para servicios que no exponen puertos HTTP.
* **üõ°Ô∏è Resiliencia de Datos:** Uso de SQLite en modo **WAL (Write-Ahead Logging)** para permitir alta concurrencia en operaciones de lectura/escritura sin bloqueos de base de datos.
* **üîî Gesti√≥n de Estado con "Debounce":** Sistema de alertas inteligente que filtra falsos positivos mediante umbrales de cambio de estado configurables y l√≥gica de reintentos autom√°tica ante fallos del webhook.

## ‚öôÔ∏è Flujo de Ejecuci√≥n del Agente

El agente opera en un bucle principal, ejecut√°ndose cada 10 segundos, coordinando la recolecci√≥n, procesamiento y notificaci√≥n.

```ascii
[ INICIO ]
    |
    v
[ 1. Cargar Configuraci√≥n (.env) ]
    |
    v
[ 2. Init Base de Datos (SQLite WAL) ]
    |
    +---> [ BUCLE PRINCIPAL (Cada 10s) ] <--------------------------+
            |                                                       |
            |-- (A) M√©tricas Sistema (CPU/RAM) [S√≠ncrono]           |
            |                                                       |
            |-- (B) Health Checks [ThreadPoolExecutor / Paralelo]   |
            |       |--> HTTP/HTTPS (Smart Request)                 |
            |       |--> Docker Socket                              |
            |       +--> Ping Internet                              |
            |                                                       |
            v                                                       |
    [ 3. Procesar Estado (Debounce Logic) ]                         |
            |                                                       |
            +--- ¬øCambio de Estado? ---> [ Enviar Alerta (N8N) ]    |
            |                                                       |
            +--- ¬øInternet OK? --------> [ Enviar Heartbeat (CF) ]  |
            |                                                       |
            v                                                       |
    [ 4. Persistencia (Guardar M√©tricas en DB) ] -------------------+
```

### Flujo de Ejecuci√≥n Detallado (Ciclo de 10s)

1. **Inicializaci√≥n:** Carga de configuraci√≥n y establecimiento de conexiones persistentes (Keep-Alive).
2. **M√©tricas de Sistema (S√≠ncrono):** Lectura instant√°nea de CPU/RAM/Disco (`psutil`).
3. **Health Checks (Paralelo)::** Se lanzan hilos concurrentes para verificar todos los servicios configurados y la conectividad a Internet.
4. **Procesamiento de Estado:** Se eval√∫an los cambios (Healthy <-> Unhealthy) contra los umbrales definidos.
5. **Notificaci√≥n/Heartbeat:** Si hay cambios cr√≠ticos o corresponde un latido, se env√≠an payloads JSON optimizados a los endpoints externos.
6. **Persistencia:** Se realiza un commit at√≥mico de todas las m√©tricas del ciclo en la base de datos local.

## üìÇ Estructura del C√≥digo

El proyecto ha sido refactorizado desde un script monol√≠tico hacia una arquitectura modular basada en responsabilidades √∫nicas (SRP):

```text
app/
‚îú‚îÄ‚îÄ main.py        # Orquestador principal de la aplicaci√≥n.
‚îú‚îÄ‚îÄ config.py      # Gesti√≥n de la configuraci√≥n y variables de entorno.
‚îú‚îÄ‚îÄ monitors.py    # Recopilaci√≥n de m√©tricas y chequeos de salud.
‚îú‚îÄ‚îÄ alerts.py      # Gesti√≥n del estado y env√≠o de notificaciones.
‚îú‚îÄ‚îÄ network.py     # Infraestructura de red y configuraci√≥n de requests.
‚îî‚îÄ‚îÄ database.py    # Funcionalidades de persistencia de datos SQLite.
```

### Descripci√≥n de M√≥dulos

* **`main.py`**: Contiene el bucle principal de ejecuci√≥n de la aplicaci√≥n. Coordina la inicializaci√≥n, la recolecci√≥n de datos, el procesamiento de estado y la persistencia de m√©tricas mediante la interacci√≥n con los dem√°s m√≥dulos.
* **`config.py`**: Centraliza la lectura de variables de entorno, la definici√≥n de constantes globales y el parseo de la configuraci√≥n de servicios a monitorizar.
* **`monitors.py`**: Agrupa las funciones responsables de obtener datos del sistema (CPU, RAM, Disco), contar contenedores Docker y realizar las comprobaciones de salud de los servicios HTTP/HTTPS y Docker.
* **`alerts.py`**: Implementa la l√≥gica de gesti√≥n de estado transitorio y estable, as√≠ como el mecanismo de env√≠o de alertas a trav√©s de webhooks N8N y la comunicaci√≥n de latidos al worker de Cloudflare.
* **`network.py`**: Provee la capa de abstracci√≥n para las operaciones de red. Incluye la configuraci√≥n de sesiones HTTP (forzando IPv4), y la funci√≥n `smart_request` con su l√≥gica de anulaci√≥n de DNS interno.
* **`database.py`**: Encapsula todas las operaciones relacionadas con la base de datos SQLite, incluyendo su inicializaci√≥n (creaci√≥n de tablas) y el guardado de las m√©tricas recolectadas en cada ciclo.

## Arquitectura y Flujo de Ejecuci√≥n

El agente opera en un bucle principal que se ejecuta cada `LOOP_INTERVAL_SECONDS` (actualmente 10 segundos). La ejecuci√≥n est√° alineada con el reloj del sistema para garantizar la consistencia de los intervalos (ej., se ejecuta a las :00, :10, :20 segundos, etc.).

Cada ciclo de ejecuci√≥n sigue un modelo de concurrencia para optimizar el tiempo y evitar bloqueos:

1. **Tarea de CPU Secuencial:** Primero, se recopilan las m√©tricas del sistema (`cpu_percent`, `ram_percent`, etc.) utilizando `psutil`. La llamada a `psutil.cpu_percent(interval=None)` es no bloqueante y mide el uso de CPU desde la √∫ltima llamada.
2. **Tareas de I/O Concurrentes:** Inmediatamente despu√©s, se utiliza un `ThreadPoolExecutor` para lanzar todas las tareas de red (que son bloqueantes por naturaleza) en paralelo. Esto incluye:
    * `check_services_health`: Verifica el estado de todos los servicios definidos en las variables de entorno.
    * `check_internet_and_ping`: Mide la conectividad y latencia a `google.com`.
    * `get_container_count`: Se conecta al socket de Docker para contar los contenedores activos.
3. **Recopilaci√≥n de Resultados:** El script espera a que todas las tareas concurrentes finalicen antes de continuar.
4. **Env√≠o de Latido (Heartbeat):** Con los resultados de las comprobaciones, se construye y env√≠a un payload al `HEARTBEAT_URL`.
5. **Procesamiento de Estado y Alertas**: Se analiza el estado del worker y de cada servicio para determinar si se ha producido un cambio de estado estable que requiera una notificaci√≥n.
6. **Persistencia en Base de Datos:** Finalmente, todas las m√©tricas y resultados del ciclo se guardan en la base de datos SQLite.

### Estimaci√≥n del Tiempo de Ciclo

El uso de `ThreadPoolExecutor` significa que el tiempo de la fase de I/O est√° determinado por la tarea m√°s lenta, no por la suma de todas. El `cycle_duration_ms` guardado en la base de datos registra la duraci√≥n real de cada ciclo para su an√°lisis.

## Monitorizaci√≥n de Servicios

La funcionalidad principal del agente es monitorizar el estado de m√∫ltiples servicios web, reportarlo al worker y generar alertas si su estado cambia de forma persistente.

### Configuraci√≥n Din√°mica

Los servicios a monitorear se configuran din√°micamente mediante variables de entorno:

1. **`SERVICE_NAMES`**: Lista separada por comas de los nombres de los servicios (ej: `SERVICE_NAMES=nextjs,strapi,umami`).
2. **`SERVICE_URL_{nombre}`**: La URL a chequear para cada nombre definido (ej: `SERVICE_URL_nextjs=https://www.ejemplo.com`).

Un servicio se considera `"healthy"` si responde con un c√≥digo `2xx` o `3xx`. De lo contrario, se marca como `"unhealthy"`.

### Configuraci√≥n Avanzada de Servicios

El monitor soporta caracter√≠sticas avanzadas para cubrir casos de uso complejos, como servicios internos o endpoints protegidos.

#### 1. Monitoreo Directo de Contenedores (`docker:`)

Para servicios de infraestructura (como Nginx, t√∫neles, bases de datos) que no exponen un puerto HTTP accesible f√°cilmente, puedes usar el protocolo `docker:`. Esto verifica directamente si el contenedor est√° en estado `running`.

* **Sintaxis:** `SERVICE_URL_<nombre>="docker:<nombre_del_contenedor>"`
* **Ejemplo:**

    ```bash
    SERVICE_URL_nginx="docker:mi-contenedor-nginx"
    ```

* **Nota:** Requiere que el agente tenga acceso al socket de Docker (`/var/run/docker.sock`), lo cual ya est√° configurado por defecto en el `docker-compose.yml`.

#### 2. Headers HTTP Personalizados

Algunos endpoints de salud requieren autenticaci√≥n o headers espec√≠ficos para responder correctamente. Puedes definirlos usando variables de entorno con el prefijo `SERVICE_HEADERS_`.

* **Sintaxis:** `SERVICE_HEADERS_<nombre>="Header1:Valor1,Header2:Valor2"`
* **Ejemplo:**

    ```bash
    # Verifica un endpoint que requiere un token o flag especial
    SERVICE_URL_api="https://mi-api.com/health"
    SERVICE_HEADERS_api="x-health-check:true,Authorization:Bearer mi-token"
    ```

### Optimizaci√≥n de Latencia (DNS Override)

Para entornos donde los servicios residen en la misma red local o servidor (ej: contenedores Docker detr√°s de un Nginx en el host), el agente permite configurar una IP de anulaci√≥n de DNS (`INTERNAL_DNS_OVERRIDE_IP`) para reducir dr√°sticamente la latencia.

* **Funcionamiento:** Si se define esta variable, el agente interceptar√° las peticiones a los servicios monitorizados, resolver√° el dominio directamente a la IP especificada, forzar√° el uso de HTTP (evitando el handshake SSL innecesario en la red interna) e inyectar√° el encabezado `Host` correcto.
* **Beneficio:** Reduce la latencia de ~50ms a ~1-3ms al saltarse la resoluci√≥n DNS externa y el enrutamiento p√∫blico.
* **Configuraci√≥n:** Ver variable `INTERNAL_DNS_OVERRIDE_IP` en `.env`.

### Payload de Estado de Salud

En cada ciclo, el agente construye un payload JSON que resume el estado de salud de los servicios y lo env√≠a al `HEARTBEAT_URL`.

* **Estructura del Payload:**

    ```json
    {
      "services": {
        "nextjs": { "status": "healthy" },
        "strapi": { "status": "unhealthy" },
        "umami": { "status": "healthy" }
      }
    }
    ```

## Gesti√≥n de Estado y Alertas

Para evitar falsas alarmas por fallos transitorios y gestionar las notificaciones de forma centralizada, el agente implementa una **arquitectura de estado unificada**.

Toda la l√≥gica de estado se gestiona a trav√©s de una √∫nica funci√≥n gen√©rica, `check_state_change`, y se almacena en un diccionario global en memoria, `global_states`. Este enfoque permite monitorear cualquier item (el worker principal o servicios individuales) usando las mismas reglas, evitando la duplicaci√≥n de c√≥digo.

### L√≥gica de Notificaci√≥n

El sistema env√≠a alertas al `N8N_WEBHOOK_URL` bajo las siguientes condiciones, incluyendo ahora mecanismos de robustez y detalle:

1. **Robustez y Reintentos:**
    * Si el env√≠o de la alerta falla (por ejemplo, timeout del webhook), el sistema reintenta autom√°ticamente hasta **3 veces** antes de desistir, asegurando que las alertas cr√≠ticas lleguen a su destino.

2. **Alertas Enriquecidas:**
    * **Servicio Ca√≠do:** Incluye la raz√≥n espec√≠fica del fallo (ej: `HTTP 500`, `Timeout`, `Container Exited`) para facilitar el diagn√≥stico inmediato.
    * **Servicio Recuperado:** Muestra la latencia actual del servicio tras la recuperaci√≥n.
    * **Timestamp:** Todas las alertas incluyen la fecha y hora exacta del evento (zona horaria configurada) para una auditor√≠a precisa.

3. **Condiciones de Disparo:**
    * **Ca√≠da de Servicio:** Tras `STATUS_CHANGE_THRESHOLD` fallos consecutivos.
    * **Recuperaci√≥n de Servicio:** Inmediata al primer √©xito.
    * **Estado del Worker:** Monitorizaci√≥n de cambios de estado del propio worker de Cloudflare con alertas contextuales.

Este mecanismo asegura que solo se notifiquen los cambios de estado confirmados, aplicando una l√≥gica consistente a todos los elementos monitoreados.

## Persistencia de Datos (Base de Datos)

Todas las m√©tricas se almacenan en una base de datos SQLite (`metrics.db`) con el modo `WAL` activado para mejorar la concurrencia de escritura/lectura.

| Columna | Tipo | Descripci√≥n |
| :--- | :--- | :--- |
| `id` | `TEXT` | UUID √∫nico del registro. |
| `timestamp_lima`| `TEXT` | Marca de tiempo en ISO8601 (zona horaria de Lima). |
| `cpu_percent` | `REAL` | Uso de CPU. |
| `ram_percent` | `REAL` | Uso de RAM (%). |
| `ram_used_mb` | `REAL` | RAM usada (MB). |
| `disk_percent`| `REAL` | Uso del disco ra√≠z (%). |
| `container_count`| `INTEGER`| Contenedores Docker activos. |
| `internet_ok` | `INTEGER`| `1` si hay conexi√≥n, `0` si no. |
| `ping_ms` | `REAL` | Latencia a `google.com`. |
| `worker_status` | `INTEGER` | C√≥digo de estado HTTP retornado por la API del Cloudflare Worker. Refleja el resultado del procesamiento del latido. <br> - `200`: **√âxito**. Latido recibido, procesado y el estado del host/servicios fue actualizado. Puede indicar un estado "recorded" (sin cambios) o "recovered" (recuperaci√≥n). <br> - `220`: **Advertencia (Ciego)**. Latido recibido y timestamp actualizado, pero la API no pudo leer el estado *anterior* de su base de datos. No se pudo determinar si hubo una recuperaci√≥n. <br> - `221`: **Advertencia (Fallo en Actualizaci√≥n de Recuperaci√≥n)**. Se detect√≥ una recuperaci√≥n, pero la API fall√≥ al actualizar su propio estado o al enviar la notificaci√≥n. <br> - `500`: **Error Cr√≠tico del Worker**. La API fall√≥ en un paso esencial (ej. escribir el timestamp inicial) y el latido fue abortado. <br> - `NULL`: **Error del Agente Local**. El script de monitorizaci√≥n no pudo contactar la API del worker (ej. timeout, error de red, DNS). |
| `cycle_duration_ms` | `INTEGER` | Duraci√≥n del ciclo de monitorizaci√≥n (ms). |
| `services_health`| `TEXT` | JSON con el estado, latencia y posible error de cada servicio. <br> Ej: `{"app": {"status": "healthy", "latency_ms": 25, "error": null}}` |

## Configuraci√≥n y Despliegue

1. **Clonar el repositorio:** `git clone https://github.com/iamseb4s/heartbeat-monitor.git && cd heartbeat-monitor`
2. **Configurar `.env`:** Copia `.env.example` a `.env` y rellena `SECRET_KEY`, `HEARTBEAT_URL`, `N8N_WEBHOOK_URL`, `SERVICE_NAMES` y las `SERVICE_URL_*` correspondientes.
3. **Ejecutar:** `docker compose up -d --build`
4. **Ver Logs:** `docker compose logs -f monitor-agent`
